{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import (\n",
    "    Input, Dense, Embedding, Conv1D, Flatten, Concatenate,\n",
    "    MaxPooling1D, Dropout, Dot, LeakyReLU\n",
    ")\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, average_precision_score\n",
    "from keras.utils import multi_gpu_model, Sequence, np_utils\n",
    "import scipy.stats as ss\n",
    "\n",
    "from utils import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option:  joint threshold:  0\n",
      "Params: {'max_kernel': 65, 'nb_filters': 16, 'pool_size': 200, 'dense_units': 8}\n",
      "The amino acids for human are  ['P', 'I', 'D', 'M', 'N', 'K', 'R', 'T', 'G', 'Y', 'C', 'V', 'A', 'Q', 'H', 'S', 'L', 'U', 'F', 'W', 'E']\n",
      "The amino acids for viruses are  ['P', 'D', 'M', 'I', 'N', 'X', 'K', 'R', 'T', 'Y', 'G', 'C', 'V', 'A', 'Q', 'H', 'S', 'L', 'F', 'W', 'E']\n",
      "finished reading embeddings\n",
      "Number of host proteins:  16627\n"
     ]
    }
   ],
   "source": [
    "MAXLEN = 1000\n",
    "epochs = 30\n",
    "num_gpus = 1\n",
    "batch_size = 1500*num_gpus\n",
    "steps = 300\n",
    "\n",
    "thres = '0'\n",
    "option = 'joint'\n",
    "tid = '0'\n",
    "embedding_file = 'data/julia_embed_cleaned.txt'\n",
    "print(\"option: \", option, \"threshold: \", thres)\n",
    "sars2_interactions = 'data/media-6.xlsx'\n",
    "sars2_sequences = 'data/2020-04-krogan-sarscov2-sequences-uniprot-mapping.xlsx'\n",
    "\n",
    "model_file = f'model_sars2_{option}_{tid}.h5'\n",
    "preds_file = f'preds_sars2_{option}_{tid}.txt'\n",
    "open_preds = open(preds_file, \"w\")\n",
    "open_preds.close()\n",
    "\n",
    "swissprot_file = 'data/swissprot-proteome.tab'\n",
    "hpi_file = 'data/train_1000.txt'\n",
    "\n",
    "params = get_params()\n",
    "\n",
    "haaindex, vaaindex = get_aaindex(swissprot_file, hpi_file)\n",
    "print(\"The amino acids for human are \", list(haaindex))\n",
    "print(\"The amino acids for viruses are \", list(vaaindex))\n",
    "embed_dict = read_embedding(embedding_file)\n",
    "hp_set, prot2embed = read_swissprot(swissprot_file, embed_dict, haaindex, first = False)\n",
    "\n",
    "positives = set()\n",
    "family_dict = {}\n",
    "pathogens = set()\n",
    "family2vp = {}\n",
    "vp2patho = {}\n",
    "vp2numPos = {}\n",
    "\n",
    "with open(hpi_file, 'r') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        items = line.strip().split('\\t')\n",
    "        if items[0] not in hp_set:\n",
    "            continue\n",
    "        if float(items[6]) >= float(thres):\n",
    "            hp = items[0]\n",
    "            vp = items[1]\n",
    "            patho = '<http://purl.obolibrary.org/obo/NCBITaxon_' + items[2] + '>'\n",
    "            if hp not in embed_dict or patho not in embed_dict:\n",
    "                continue\n",
    "            if len(items[5]) > MAXLEN:\n",
    "                continue\n",
    "            family = '<http://purl.obolibrary.org/obo/NCBITaxon_' + items[3] + '>'\n",
    "            prot2embed[vp] = to_onehot(items[5], vaaindex)\n",
    "            family_dict[patho] = family\n",
    "            positives.add((hp, vp, patho, family))\n",
    "            pathogens.add(patho)\n",
    "            if family not in family2vp:\n",
    "                family2vp[family] = set()\n",
    "            family2vp[family].add(vp)\n",
    "            vp2patho[vp] = patho\n",
    "            if vp not in vp2numPos:\n",
    "                vp2numPos[vp] = 0\n",
    "            vp2numPos[vp] += 1\n",
    "\n",
    "dfs_interaction = pd.read_excel(sars2_interactions, sheet_name = None, skiprows=1)\n",
    "for index, row in dfs_interaction[\"Sheet1\"].iterrows():\n",
    "    hp = row['Preys']\n",
    "    vp = row['Bait']\n",
    "    patho = '<http://purl.obolibrary.org/obo/NCBITaxon_2697049>'\n",
    "    family = '<http://purl.obolibrary.org/obo/NCBITaxon_11118>'\n",
    "    if hp not in embed_dict or hp not in prot2embed:\n",
    "            continue\n",
    "    family_dict[patho] = family\n",
    "    positives.add((hp, vp, patho, family))\n",
    "    pathogens.add(patho)\n",
    "    if family not in family2vp:\n",
    "        family2vp[family] = set()\n",
    "    family2vp[family].add(vp)\n",
    "    vp2patho[vp] = patho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(gname2unip) 142\n"
     ]
    }
   ],
   "source": [
    "with open('data/sars1_seqs.txt', 'r') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        items = line.strip().split('\\t')\n",
    "        seq = items[2]\n",
    "        if len(seq) > MAXLEN:\n",
    "            seq = seq[:MAXLEN]\n",
    "        if len(seq) > MAXLEN or len(seq) == 0:\n",
    "            continue\n",
    "        vp = \"SARS1_\" + items[1]\n",
    "        prot2embed[vp] = to_onehot(seq, vaaindex)\n",
    "\n",
    "gname2unip = {\"BTF3\":\"P20290\", \"BAP1\":\"Q92560\", \"ALB\":\"P02768\", \"NMB\":\"P08949\", \"BRF1\":\"Q92994\", \n",
    "              \"CCNL1\":\"Q9UK58\", \"PCM1\": \"Q15154\", \"TRAF2\": \"Q12933\"}\n",
    "with open('data/genename2uniprot.tab', 'r') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        items = line.strip().split('\\t')\n",
    "        gname = items[0]\n",
    "        unip = items[1]\n",
    "        full = items[2]\n",
    "        if gname in gname2unip:\n",
    "            continue\n",
    "        gname2unip[gname] = unip\n",
    "print(\"len(gname2unip)\", len(gname2unip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppi_file = \"data/12967_2020_2480_MOESM1_ESM.xlsx\"\n",
    "dfs = pd.read_excel(ppi_file, sheet_name = \"Table S1\")\n",
    "\n",
    "for index, row in dfs.iterrows():\n",
    "    if row[\"VIRUS\"] != \"SARS-CoV\" or row[\"SPECIES\"] != \"Human\":\n",
    "        continue\n",
    "    vp = \"SARS1_\" + row[\"VIRAL PROTEIN\"]\n",
    "    hp = gname2unip[row[\"CELLULAR PROTEIN (Uniprot)\"]]\n",
    "    if vp not in prot2embed or hp not in prot2embed or hp not in embed_dict:\n",
    "        continue\n",
    "    family = '<http://purl.obolibrary.org/obo/NCBITaxon_694009>'\n",
    "    patho = '<http://purl.obolibrary.org/obo/NCBITaxon_694009>'\n",
    "    family_dict[patho] = family\n",
    "    positives.add((hp, vp, patho, family))\n",
    "    pathogens.add(patho)\n",
    "    if family not in family2vp:\n",
    "        family2vp[family] = set()\n",
    "    family2vp[family].add(vp)\n",
    "    vp2patho[vp] = patho\n",
    "    if vp not in vp2numPos:\n",
    "        vp2numPos[vp] = 0\n",
    "    vp2numPos[vp] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positives:  25107\n",
      "Number of pathogens:  294\n",
      "Number of families:  16\n",
      "Number of viral proteins:  1118\n"
     ]
    }
   ],
   "source": [
    "vp_set = set(vp2patho.keys())\n",
    "families = set(family2vp.keys())\n",
    "print('Number of positives: ', len(positives))\n",
    "print('Number of pathogens: ', len(pathogens))\n",
    "print('Number of families: ', len(families))\n",
    "print('Number of viral proteins: ', len(vp_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_seq = pd.read_excel(sars2_sequences)\n",
    "for index, row in dfs_seq.iterrows():\n",
    "    vp = row['Krogan name']\n",
    "    seq = row['Sequence']\n",
    "    if '*' == seq[len(seq)-1]:\n",
    "        seq = seq[:len(seq)-1]\n",
    "    prot2embed[vp] = to_onehot(seq, vaaindex)\n",
    "    \n",
    "config = tf.ConfigProto()\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "counter = 0\n",
    "family_aucs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test family 1: <http://purl.obolibrary.org/obo/NCBITaxon_11118>\n",
      "Train families:  12 validation families 3\n",
      "Number of viral proteins in train, val and test:  953 138 27\n",
      "Number of positives in train families: 22736\n",
      "Number of positives in val families: 2093\n",
      "Number of positives in test families: 278\n",
      "Number of triples in train, val, test 31624315 231336 448929\n",
      "(?, 993, 16)\n",
      "(?, 985, 16)\n",
      "(?, 977, 16)\n",
      "(?, 969, 16)\n",
      "(?, 961, 16)\n",
      "(?, 953, 16)\n",
      "(?, 945, 16)\n",
      "(?, 937, 16)\n",
      "(?, 993, 16)\n",
      "(?, 985, 16)\n",
      "(?, 977, 16)\n",
      "(?, 969, 16)\n",
      "(?, 961, 16)\n",
      "(?, 953, 16)\n",
      "(?, 945, 16)\n",
      "(?, 937, 16)\n",
      "taxon  1  epoch  0\n",
      "Epoch 1/1\n",
      " - 265s - loss: 0.6093 - acc: 0.7127\n",
      "The ROCAUC for the val families in this epoch is  0.7409973711040416\n",
      "Saving current model...\n",
      "ROCAUC: 0.7211, AUPRC: 0.0013\n",
      "taxon  1  epoch  1\n",
      "Epoch 1/1\n",
      " - 269s - loss: 0.5536 - acc: 0.7785\n",
      "The ROCAUC for the val families in this epoch is  0.7970972083216561\n",
      "Saving current model...\n",
      "ROCAUC: 0.7364, AUPRC: 0.0013\n",
      "taxon  1  epoch  2\n",
      "Epoch 1/1\n",
      " - 271s - loss: 0.5208 - acc: 0.8071\n",
      "The ROCAUC for the val families in this epoch is  0.7934462077838321\n",
      "ROCAUC: 0.7470, AUPRC: 0.0015\n",
      "taxon  1  epoch  3\n",
      "Epoch 1/1\n",
      " - 273s - loss: 0.4927 - acc: 0.8208\n",
      "The ROCAUC for the val families in this epoch is  0.7858386037716913\n",
      "ROCAUC: 0.7475, AUPRC: 0.0015\n",
      "taxon  1  epoch  4\n",
      "Epoch 1/1\n",
      " - 268s - loss: 0.4699 - acc: 0.8277\n",
      "The ROCAUC for the val families in this epoch is  0.7674565860995715\n",
      "ROCAUC: 0.7445, AUPRC: 0.0015\n",
      "taxon  1  epoch  5\n",
      "Epoch 1/1\n",
      " - 268s - loss: 0.4534 - acc: 0.8317\n",
      "The ROCAUC for the val families in this epoch is  0.7858614890819563\n",
      "ROCAUC: 0.7518, AUPRC: 0.0015\n",
      "taxon  1  epoch  6\n",
      "Epoch 1/1\n",
      " - 268s - loss: 0.4373 - acc: 0.8402\n",
      "The ROCAUC for the val families in this epoch is  0.7501270092515114\n",
      "ROCAUC: 0.7526, AUPRC: 0.0015\n",
      "taxon  1  epoch  7\n",
      "Epoch 1/1\n",
      " - 268s - loss: 0.4216 - acc: 0.8472\n",
      "The ROCAUC for the val families in this epoch is  0.7784266435790383\n",
      "ROCAUC: 0.7576, AUPRC: 0.0016\n",
      "taxon  1  epoch  8\n",
      "Epoch 1/1\n",
      " - 269s - loss: 0.4086 - acc: 0.8506\n",
      "The ROCAUC for the val families in this epoch is  0.7674749060191771\n",
      "ROCAUC: 0.7516, AUPRC: 0.0015\n",
      "taxon  1  epoch  9\n",
      "Epoch 1/1\n",
      " - 271s - loss: 0.3986 - acc: 0.8530\n",
      "The ROCAUC for the val families in this epoch is  0.7838770155743848\n",
      "ROCAUC: 0.7553, AUPRC: 0.0016\n",
      "taxon  1  epoch  10\n",
      "Epoch 1/1\n",
      " - 269s - loss: 0.3866 - acc: 0.8572\n",
      "The ROCAUC for the val families in this epoch is  0.769468983416344\n",
      "ROCAUC: 0.7460, AUPRC: 0.0015\n",
      "taxon  1  epoch  11\n",
      "Epoch 1/1\n",
      " - 270s - loss: 0.3792 - acc: 0.8588\n",
      "The ROCAUC for the val families in this epoch is  0.7854984587205703\n",
      "ROCAUC: 0.7399, AUPRC: 0.0015\n",
      "taxon  1  epoch  12\n",
      "Epoch 1/1\n",
      " - 271s - loss: 0.3718 - acc: 0.8601\n",
      "The ROCAUC for the val families in this epoch is  0.7866613661588389\n",
      "ROCAUC: 0.7452, AUPRC: 0.0015\n",
      "taxon  1  epoch  13\n",
      "Epoch 1/1\n",
      " - 270s - loss: 0.3640 - acc: 0.8623\n",
      "The ROCAUC for the val families in this epoch is  0.7876943814071665\n",
      "ROCAUC: 0.7432, AUPRC: 0.0017\n",
      "taxon  1  epoch  14\n",
      "Epoch 1/1\n",
      " - 270s - loss: 0.3585 - acc: 0.8620\n",
      "The ROCAUC for the val families in this epoch is  0.8010924847502667\n",
      "Saving current model...\n",
      "ROCAUC: 0.7359, AUPRC: 0.0014\n",
      "taxon  1  epoch  15\n",
      "Epoch 1/1\n",
      " - 270s - loss: 0.3515 - acc: 0.8641\n",
      "The ROCAUC for the val families in this epoch is  0.7820813362371788\n",
      "ROCAUC: 0.7252, AUPRC: 0.0014\n",
      "taxon  1  epoch  16\n",
      "Epoch 1/1\n",
      " - 271s - loss: 0.3473 - acc: 0.8650\n",
      "The ROCAUC for the val families in this epoch is  0.7809356357677686\n",
      "ROCAUC: 0.7153, AUPRC: 0.0015\n",
      "taxon  1  epoch  17\n",
      "Epoch 1/1\n",
      " - 270s - loss: 0.3423 - acc: 0.8664\n",
      "The ROCAUC for the val families in this epoch is  0.7791208163871384\n",
      "ROCAUC: 0.7250, AUPRC: 0.0015\n",
      "taxon  1  epoch  18\n",
      "Epoch 1/1\n",
      " - 271s - loss: 0.3384 - acc: 0.8668\n",
      "The ROCAUC for the val families in this epoch is  0.7797797968172522\n",
      "ROCAUC: 0.7227, AUPRC: 0.0015\n",
      "taxon  1  epoch  19\n",
      "Epoch 1/1\n",
      " - 270s - loss: 0.3337 - acc: 0.8676\n",
      "The ROCAUC for the val families in this epoch is  0.780697983268011\n",
      "ROCAUC: 0.7111, AUPRC: 0.0013\n",
      "taxon  1  epoch  20\n",
      "Epoch 1/1\n",
      " - 270s - loss: 0.3312 - acc: 0.8677\n",
      "The ROCAUC for the val families in this epoch is  0.7799840920572501\n",
      "ROCAUC: 0.7067, AUPRC: 0.0013\n",
      "taxon  1  epoch  21\n",
      "Epoch 1/1\n",
      " - 270s - loss: 0.3268 - acc: 0.8696\n",
      "The ROCAUC for the val families in this epoch is  0.7676072366967107\n",
      "ROCAUC: 0.6909, AUPRC: 0.0013\n",
      "taxon  1  epoch  22\n",
      "Epoch 1/1\n",
      " - 271s - loss: 0.3235 - acc: 0.8705\n",
      "The ROCAUC for the val families in this epoch is  0.7670919675949842\n",
      "ROCAUC: 0.6790, AUPRC: 0.0011\n",
      "taxon  1  epoch  23\n",
      "Epoch 1/1\n",
      " - 270s - loss: 0.3216 - acc: 0.8711\n",
      "The ROCAUC for the val families in this epoch is  0.7584096189340217\n",
      "ROCAUC: 0.6844, AUPRC: 0.0011\n",
      "taxon  1  epoch  24\n",
      "Epoch 1/1\n",
      " - 271s - loss: 0.3193 - acc: 0.8713\n",
      "The ROCAUC for the val families in this epoch is  0.7536282074524103\n",
      "ROCAUC: 0.6832, AUPRC: 0.0012\n",
      "taxon  1  epoch  25\n",
      "Epoch 1/1\n",
      " - 270s - loss: 0.3155 - acc: 0.8721\n",
      "The ROCAUC for the val families in this epoch is  0.7508681448296313\n",
      "ROCAUC: 0.6752, AUPRC: 0.0012\n",
      "taxon  1  epoch  26\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9050179d4f35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m                             \u001b[0mmax_queue_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                             workers = 1)\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         y_score = model.predict_generator(generator=val_gen, verbose=2,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for test_family in [\"<http://purl.obolibrary.org/obo/NCBITaxon_11118>\"]:\n",
    "    counter+=1\n",
    "    K.clear_session()\n",
    "    print('Test family %d: %s' % (counter, test_family))\n",
    "    tv_families = list(families - set([test_family]))\n",
    "    val_families = set(np.random.choice(tv_families, size = int(len(tv_families)/5), replace=False))\n",
    "    train_families = set(tv_families) - val_families\n",
    "    train_families.add('<http://purl.obolibrary.org/obo/NCBITaxon_694009>')\n",
    "    val_families = val_families - {'<http://purl.obolibrary.org/obo/NCBITaxon_694009>'}\n",
    "#     train_families = {'<http://purl.obolibrary.org/obo/NCBITaxon_694009>'}\n",
    "#     val_families = {'<http://purl.obolibrary.org/obo/NCBITaxon_694009>'}\n",
    "    print('Train families: ', len(train_families), 'validation families', len(val_families))\n",
    "\n",
    "    train_vps = set()\n",
    "    for family in train_families:\n",
    "        train_vps = train_vps | family2vp[family]\n",
    "    val_vps = vp_set - family2vp[test_family] - train_vps\n",
    "    #val_vps = family2vp[family]\n",
    "    print(\"Number of viral proteins in train, val and test: \", len(train_vps), len(val_vps), len(family2vp[test_family]))\n",
    "    \n",
    "    triple_train = get_triple(positives, train_families, hp_set, train_vps, vp2patho, 'train')\n",
    "    triple_val, numPos_val = get_triple(positives, val_families, hp_set, val_vps,  vp2patho, 'val')\n",
    "    triple_test, numPos_test = get_triple(positives, [test_family], hp_set, family2vp[test_family], vp2patho, 'test')\n",
    "    print(\"Number of triples in train, val, test\", len(triple_train), len(triple_val), len(triple_test))\n",
    "    \n",
    "    if option ==\"seq\":\n",
    "        seq1, flat1 = get_seq_model(params)\n",
    "        seq2, flat2 = get_seq_model(params)\n",
    "    if option ==\"joint\":\n",
    "        seq1, pheno1, flat1 = get_joint_model(params)\n",
    "        seq2, pheno2, flat2 = get_joint_model(params)\n",
    "    if option == \"pheno\":\n",
    "        seq1, flat1 = get_seq_model(params)\n",
    "        seq2, pheno2, flat2 = get_joint_model(params)\n",
    "        flat2 = Dense(8)(flat2)\n",
    "        flat2 = LeakyReLU(alpha=0.1)(flat2)\n",
    "        flat2 = Dropout(0.5)(flat2)\n",
    "    if option == \"go\":\n",
    "        seq1, pheno1, flat1 = get_joint_model(params)\n",
    "        seq2, flat2 = get_seq_model(params)\n",
    "        flat1 = Dense(8)(flat1)\n",
    "        flat1 = LeakyReLU(alpha=0.1)(flat1)\n",
    "        flat1 = Dropout(0.5)(flat1)\n",
    "    concat = Dot(axes=-1, normalize=True)([flat1,flat2])\n",
    "    output = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "    if option ==\"seq\":\n",
    "        model = Model(inputs=[seq1, seq2], outputs=output)\n",
    "    if option ==\"joint\":\n",
    "        model = Model(inputs=[seq1, seq2, pheno1, pheno2], outputs=output)\n",
    "    if option == \"pheno\":\n",
    "        model = Model(inputs=[seq1, seq2, pheno2], outputs=output)\n",
    "    if option == \"go\":\n",
    "        model = Model(inputs=[seq1, seq2, pheno1], outputs=output)\n",
    "    train_gen, val_gen, test_gen = get_generators(triple_train, triple_val, triple_test, batch_size, prot2embed, option, embed_dict)\n",
    "        \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    val_maxauc = 0\n",
    "    for i in range(epochs):\n",
    "        print('taxon ', counter, ' epoch ', i)\n",
    "        history = model.fit_generator(generator=train_gen,\n",
    "                            epochs=1,\n",
    "                            steps_per_epoch = steps,\n",
    "                            verbose=2,\n",
    "                            max_queue_size = 50,\n",
    "                            use_multiprocessing=False,\n",
    "                            workers = 1)\n",
    "\n",
    "        y_score = model.predict_generator(generator=val_gen, verbose=2,\n",
    "                                           steps=int(np.ceil(len(triple_val)/batch_size)), \n",
    "                                            max_queue_size = 50, workers = 1)\n",
    "            \n",
    "        y_true = np.concatenate((np.ones(numPos_val), np.zeros(len(triple_val) - numPos_val)))\n",
    "        \n",
    "        val_auc = roc_auc_score(y_true, y_score)\n",
    "        print('The ROCAUC for the val families in this epoch is ', val_auc)\n",
    "        if val_auc > val_maxauc:\n",
    "            print('Saving current model...')\n",
    "            model.save(model_file)\n",
    "            val_maxauc = val_auc\n",
    "        \n",
    "        y_score = model.predict_generator(generator=test_gen,\n",
    "                                    verbose=2,steps=np.ceil(len(triple_test)/batch_size), \n",
    "                                    max_queue_size = 30, use_multiprocessing=False, workers = 1)\n",
    "\n",
    "        y_true = np.concatenate((np.ones(numPos_test), np.zeros(len(triple_test) - numPos_test)))\n",
    "        auprc = average_precision_score(y_true, y_score)\n",
    "        test_auc = roc_auc_score(y_true, y_score)\n",
    "        family_aucs.append((test_auc))\n",
    "        print(\"ROCAUC: %.4f, AUPRC: %.4f\" % (test_auc, auprc))\n",
    "\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    model = load_model(model_file)\n",
    "    y_score = model.predict_generator(generator=test_gen,\n",
    "                                    verbose=2,steps=np.ceil(len(triple_test)/batch_size), \n",
    "                                    max_queue_size = 30, use_multiprocessing=False, workers = 1)\n",
    "\n",
    "    y_true = np.concatenate((np.ones(numPos_test), np.zeros(len(triple_test) - numPos_test)))\n",
    "    auprc = average_precision_score(y_true, y_score)\n",
    "    test_auc = roc_auc_score(y_true, y_score)\n",
    "    family_aucs.append((test_auc))\n",
    "    print(\"ROCAUC: %.4f, AUPRC: %.4f\" % (test_auc, auprc))\n",
    "    \n",
    "    with open(preds_file, 'a+') as f:\n",
    "        for i in range(triple_test.shape[0]):\n",
    "            f.write(\"%s\\t%s\\t%s\\t%s\\t%f\\t%s\\n\" % (triple_test[i,1], triple_test[i,0], triple_test[i,2], test_family, y_score[i], i<numPos_test))\n",
    "    \n",
    "print(\"Mean ROCAUC of test families: %.4f\" % (np.mean(family_aucs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
